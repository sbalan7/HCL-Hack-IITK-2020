from sklearn.ensemble import RandomForestClassifier
import pandas as pd
import numpy as np
import pickle
import json
import os


def dynamic_data_extract(path):
    dataline = pd.DataFrame()
    with open(path) as f:
        data = json.load(f)

        # Extract name hash
        try:
            x = data['target']['file']['sha256']
        except:
            print('File hash misssing for file {}'.format(path))
            x = 0
        finally:
            dataline['name'] = x

        # Extract scores
        try:
            x = data['info']['score']
        except:
            print('File score misssing for file {}'.format(path))
            x = 0
        finally:
            dataline['score'] = x

        # Extract size
        try:
            x = data['target']['file']['size']
        except:
            print('File size misssing for file {}'.format(path))
            x = 0
        finally:
            dataline['size'] = x

        # Extract source
        try:
            x = data['info']['route']
            if x == 'none':
                x = 0
            else:
                x = 1
        except:
            print('File route misssing for file {}'.format(path))
            x = 0
        finally:
            dataline['route'] = x
        
        if 'virustotal' in data.keys():
            dataline['virus'] = 1
        else:
            dataline['virus'] = 0

    return dataline

def dynamic_predict(dataline):
    prediction = dynamic_model.predict(dataline)
    if prediction == 0:
        return {dataline['name']: 'benign'}
    else:
        return {dataline['name']: 'malware'}

dynamic_model = pickle.load(open(os.path.join('Dynamic-Analysis', 'dynamic_model.dtc')))


def static_data_extract(path):
    # Feed path  i.e.
    # test/static/hash  in path arguement
    import sys
    sys.path.insert(1, 'Static-Analysis')

    from feature_extraction import parse_eng_example, parse_single_example, get_entropy, useful_words
    from feature_extraction import raw_features, engineered_features
    words1 = pd.read_csv("MostCommonWords-Benign.csv")
    words2 = pd.read_csv("MostCommonWords-Malware.csv")
    words = pd.merge(left=words2, right=words1)
    words.drop("Unnamed: 0", axis=1, inplace=True)

    all_data = []
    all_data2 = []

    p = os.path.join(path, 'Structure_Info.txt')
    p_string = os.path.join(path, "String.txt")
    sha = os.path.basename(os.path.normpath(path))

    keywords = useful_words(p_string)

    data = {}
    data2 = {}
    data = parse_single_example(p, raw_features, data)
    data2 = parse_eng_example(p, engineered_features, data2)
    entropy = get_entropy(p)
    if data is None or data2 is None:
        print("Error in encoding for file " + str(sha))
    else:
        data["name"] = sha
        data2["name"] = sha
        if entropy is not None:
            data2["Entropy:"] = entropy
        else:
            data2["Entropy:"] = 0
        all_data.append(data)
        all_data2.append(data2)

    df1 = pd.DataFrame(all_data)
    df2 = pd.DataFrame(all_data2)
    df = pd.merge(left=df1, right=df2, on="name")
    df = df.drop("Name:", axis=1)

    clf = pickle.load(open("Static-Analysis/static_model.pkl", 'rb'))

    data = pd.read_csv("Static-Analysis/Data.csv")
    data = data.drop(['name', 'Unnamed: 0', "Name:", "Unnamed: 0.1"], axis=1)
    from sklearn.preprocessing import LabelEncoder

    le = LabelEncoder()
    X = data.drop(['target'], axis=1)
    cols = X.columns

    for col in cols:
        if col != "Entropy:" and col not in words:
            le.fit(X[col].astype(str))
            df[col] = le.transform(df[col].astype(str))

    for word in words:
        if word in keywords:
            df[word] = 1
        else:
            df[word] = 0

    X_inp = df.drop("name", axis=1)

    y_pred = clf.predict(X_inp)
    y_pred = np.round(y_pred)

    preds = []
    for pred in y_pred:
        if pred == 1:
            preds.append("Malware")
        else:
            preds.append("Benign")

    preds_df = {"Name":df["name"], "Prediction Result" : preds}
    preds_df = pd.DataFrame(preds_df)

    return preds_df



test_dir_path = ''
test_list = os.listdir(test_dir_path)
for h in test_list:
    p = os.path.join(test_dir_path, h)
    q = os.listdir(p)
    if len(q) == 2:
        # Static Analysis
    else:
        # Dynamic Analysis

